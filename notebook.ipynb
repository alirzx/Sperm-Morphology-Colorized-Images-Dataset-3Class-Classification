{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sperm Morphology Colorized Images Dataset Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading and creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 18:50:31,264 - INFO - Created DataFrame with 4200 images\n",
      "2025-06-01 18:50:31,270 - INFO - Train set: 3000 images\n",
      "2025-06-01 18:50:31,272 - INFO -   Normal_Sperm: 1000 images\n",
      "2025-06-01 18:50:31,276 - INFO -   Non-Sperm: 1000 images\n",
      "2025-06-01 18:50:31,280 - INFO -   Abnormal_Sperm: 1000 images\n",
      "2025-06-01 18:50:31,283 - INFO - Validation set: 600 images\n",
      "2025-06-01 18:50:31,286 - INFO -   Normal_Sperm: 200 images\n",
      "2025-06-01 18:50:31,289 - INFO -   Non-Sperm: 200 images\n",
      "2025-06-01 18:50:31,290 - INFO -   Abnormal_Sperm: 200 images\n",
      "2025-06-01 18:50:31,290 - INFO - Test set: 600 images\n",
      "2025-06-01 18:50:31,290 - INFO -   Normal_Sperm: 200 images\n",
      "2025-06-01 18:50:31,297 - INFO -   Non-Sperm: 200 images\n",
      "2025-06-01 18:50:31,297 - INFO -   Abnormal_Sperm: 200 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 18:50:31,333 - INFO - DataFrame saved to O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\\dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_dataframe(data_dir, save_dir):\n",
    "    \"\"\"\n",
    "    Create DataFrame for the Sperm Morphology dataset based on specified directories.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Root path to dataset directories (containing 'train', 'validation', 'test').\n",
    "        save_dir (str): Directory to save DataFrame and debug logs.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with image paths, class labels, and split information.\n",
    "    \"\"\"\n",
    "    # Define the splits and classes\n",
    "    splits = ['train', 'validation', 'test']\n",
    "    classes = ['Normal_Sperm', 'Non-Sperm', 'Abnormal_Sperm']\n",
    "    \n",
    "    # Valid image extensions\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Iterate through each split and class\n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "        if not os.path.isdir(split_dir):\n",
    "            logger.error(f\"Split directory does not exist: {split_dir}\")\n",
    "            raise FileNotFoundError(f\"Split directory not found: {split_dir}\")\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                logger.error(f\"Class directory does not exist: {class_dir}\")\n",
    "                raise FileNotFoundError(f\"Class directory not found: {class_dir}\")\n",
    "            \n",
    "            # Collect image paths\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if os.path.splitext(img_file)[1].lower() in valid_extensions:\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    data.append({\n",
    "                        \"image_path\": img_path,\n",
    "                        \"class_label\": class_name,\n",
    "                        \"split\": split\n",
    "                    })\n",
    "                else:\n",
    "                    logger.warning(f\"Invalid image extension for file: {img_file}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    if df.empty:\n",
    "        logger.error(\"No valid images found in dataset!\")\n",
    "        raise ValueError(\"No valid images found.\")\n",
    "    \n",
    "    # Log dataset statistics\n",
    "    logger.info(f\"Created DataFrame with {len(df)} images\")\n",
    "    for split in splits:\n",
    "        split_count = df[df['split'] == split].shape[0]\n",
    "        logger.info(f\"{split.capitalize()} set: {split_count} images\")\n",
    "        for class_name in classes:\n",
    "            class_count = df[(df['split'] == split) & (df['class_label'] == class_name)].shape[0]\n",
    "            logger.info(f\"  {class_name}: {class_count} images\")\n",
    "    \n",
    "    # Save DataFrame\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df_path = os.path.join(save_dir, \"dataset.csv\")\n",
    "    df.to_csv(df_path, index=False)\n",
    "    logger.info(f\"DataFrame saved to {df_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\Dataset\\archive (1)\\dataset\"\n",
    "save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\"\n",
    "df = create_dataframe(data_dir, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def analyze_dataset(df, save_dir=\"plots\", num_samples=3):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the Sperm Morphology Colorized dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with image paths, class labels, and splits.\n",
    "        save_dir (str): Directory to save plots and statistics.\n",
    "        num_samples (int): Number of sample images to visualize per class.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with image statistics (dimensions, brightness, etc.).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # --- DataFrame Inspection ---\n",
    "    logger.info(\"DataFrame Analysis:\")\n",
    "    logger.info(f\"DataFrame shape: {df.shape}\")\n",
    "    logger.info(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isna().sum()\n",
    "    logger.info(\"NaN values per column:\")\n",
    "    for col, count in nan_counts.items():\n",
    "        logger.info(f\"  {col}: {count}\")\n",
    "    \n",
    "    # Describe DataFrame\n",
    "    logger.info(\"DataFrame description:\")\n",
    "    logger.info(df.describe(include='all'))\n",
    "    \n",
    "    # --- Class Distribution Analysis ---\n",
    "    class_counts = df.groupby(['split', 'class_label']).size().unstack(fill_value=0)\n",
    "    logger.info(\"Class distribution by split:\")\n",
    "    logger.info(class_counts)\n",
    "    \n",
    "    # Plot 1: Class distribution bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    class_counts.plot(kind='bar', stacked=False)\n",
    "    plt.title(\"Class Distribution by Split\")\n",
    "    plt.xlabel(\"Split\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.legend(title=\"Class\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"class_distribution_bar.png\"))\n",
    "    plt.close()\n",
    "    logger.info(\"Saved class distribution bar plot\")\n",
    "\n",
    "    # Plot 2: Class distribution pie chart (overall)\n",
    "    overall_class_counts = df['class_label'].value_counts()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(overall_class_counts, labels=overall_class_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(\"Overall Class Distribution\")\n",
    "    plt.savefig(os.path.join(save_dir, \"class_distribution_pie.png\"))\n",
    "    plt.close()\n",
    "    logger.info(\"Saved class distribution pie plot\")\n",
    "\n",
    "    # --- Image Properties Analysis ---\n",
    "    image_stats = []\n",
    "    brightness_values = []\n",
    "    channel_means = {'R': [], 'G': [], 'B': []}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img = cv2.imread(row['image_path'])\n",
    "        if img is None:\n",
    "            logger.warning(f\"Failed to load image: {row['image_path']}\")\n",
    "            continue\n",
    "        \n",
    "        # Image dimensions\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Brightness (mean intensity across all channels)\n",
    "        brightness = np.mean(img)\n",
    "        brightness_values.append(brightness)\n",
    "        \n",
    "        # Channel-wise means (BGR to RGB)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        channel_means['R'].append(np.mean(img_rgb[:, :, 0]))\n",
    "        channel_means['G'].append(np.mean(img_rgb[:, :, 1]))\n",
    "        channel_means['B'].append(np.mean(img_rgb[:, :, 2]))\n",
    "        \n",
    "        image_stats.append({\n",
    "            \"image_path\": row['image_path'],\n",
    "            \"class_label\": row['class_label'],\n",
    "            \"split\": row['split'],\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"brightness\": brightness\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    stats_df = pd.DataFrame(image_stats)\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_path = os.path.join(save_dir, \"image_stats.csv\")\n",
    "    stats_df.to_csv(stats_path, index=False)\n",
    "    logger.info(f\"Saved image statistics to {stats_path}\")\n",
    "    \n",
    "    # Log summary statistics\n",
    "    if not stats_df.empty:\n",
    "        logger.info(\"Image statistics summary:\")\n",
    "        logger.info(f\"Mean dimensions: {stats_df['width'].mean():.0f}x{stats_df['height'].mean():.0f} pixels\")\n",
    "        logger.info(f\"Mean brightness: {stats_df['brightness'].mean():.2f} ± {stats_df['brightness'].std():.2f}\")\n",
    "        logger.info(f\"RGB channel means: R={np.mean(channel_means['R']):.2f}, G={np.mean(channel_means['G']):.2f}, B={np.mean(channel_means['B']):.2f}\")\n",
    "\n",
    "    # Plot 3: Image dimensions scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=stats_df, x='width', y='height', hue='class_label', style='split')\n",
    "    plt.title(\"Image Dimensions by Class and Split\")\n",
    "    plt.xlabel(\"Width (pixels)\")\n",
    "    plt.ylabel(\"Height (pixels)\")\n",
    "    plt.savefig(os.path.join(save_dir, \"image_dimensions_scatter.png\"))\n",
    "    plt.close()\n",
    "    logger.info(\"Saved image dimensions scatter plot\")\n",
    "\n",
    "    # Plot 4: Brightness distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=stats_df, x='brightness', hue='class_label', multiple='stack', bins=30)\n",
    "    plt.title(\"Brightness Distribution by Class\")\n",
    "    plt.xlabel(\"Mean Brightness\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(os.path.join(save_dir, \"brightness_distribution.png\"))\n",
    "    plt.close()\n",
    "    logger.info(\"Saved brightness distribution plot\")\n",
    "\n",
    "    # Plot 5: RGB channel distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for channel, values in channel_means.items():\n",
    "        sns.kdeplot(values, label=channel)\n",
    "    plt.title(\"RGB Channel Intensity Distribution\")\n",
    "    plt.xlabel(\"Mean Intensity\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, \"rgb_channel_distribution.png\"))\n",
    "    plt.close()\n",
    "    logger.info(\"Saved RGB channel distribution plot\")\n",
    "\n",
    "    # Plot 6: Sample visualizations (num_samples per class)\n",
    "    classes = df['class_label'].unique()\n",
    "    for class_name in classes:\n",
    "        class_df = df[df['class_label'] == class_name].sample(min(num_samples, len(df[df['class_label'] == class_name])), random_state=42)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for idx, (_, row) in enumerate(class_df.iterrows()):\n",
    "            img = cv2.imread(row['image_path'])\n",
    "            if img is None:\n",
    "                logger.warning(f\"Skipping visualization for {row['image_path']}\")\n",
    "                continue\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(1, num_samples, idx + 1)\n",
    "            plt.imshow(img_rgb)\n",
    "            plt.title(f\"{class_name}\\n{os.path.basename(row['image_path'])}\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"sample_visualization_{class_name}.png\"))\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved sample visualization for {class_name}\")\n",
    "\n",
    "    return stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 18:55:30,034 - INFO - DataFrame Analysis:\n",
      "2025-06-01 18:55:30,037 - INFO - DataFrame shape: (4200, 3)\n",
      "2025-06-01 18:55:30,039 - INFO - Columns: ['image_path', 'class_label', 'split']\n",
      "2025-06-01 18:55:30,039 - INFO - NaN values per column:\n",
      "2025-06-01 18:55:30,039 - INFO -   image_path: 0\n",
      "2025-06-01 18:55:30,039 - INFO -   class_label: 0\n",
      "2025-06-01 18:55:30,039 - INFO -   split: 0\n",
      "2025-06-01 18:55:30,039 - INFO - DataFrame description:\n",
      "2025-06-01 18:55:30,064 - INFO -                                                image_path   class_label  split\n",
      "count                                                4200          4200   4200\n",
      "unique                                               4200             3      3\n",
      "top     O:\\O drive\\AI\\my project\\medical image project...  Normal_Sperm  train\n",
      "freq                                                    1          1400   3000\n",
      "2025-06-01 18:55:30,079 - INFO - Class distribution by split:\n",
      "2025-06-01 18:55:30,079 - INFO - class_label  Abnormal_Sperm  Non-Sperm  Normal_Sperm\n",
      "split                                               \n",
      "test                    200        200           200\n",
      "train                  1000       1000          1000\n",
      "validation              200        200           200\n",
      "2025-06-01 18:55:30,364 - INFO - Saved class distribution bar plot\n",
      "2025-06-01 18:55:30,583 - INFO - Saved class distribution pie plot\n",
      "2025-06-01 18:55:35,092 - INFO - Saved image statistics to O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\\image_stats.csv\n",
      "2025-06-01 18:55:35,092 - INFO - Image statistics summary:\n",
      "2025-06-01 18:55:35,092 - INFO - Mean dimensions: 171x168 pixels\n",
      "2025-06-01 18:55:35,099 - INFO - Mean brightness: 125.19 ± 36.91\n",
      "2025-06-01 18:55:35,099 - INFO - RGB channel means: R=234.45, G=100.65, B=40.46\n",
      "2025-06-01 18:55:35,739 - INFO - Saved image dimensions scatter plot\n",
      "2025-06-01 18:55:36,193 - INFO - Saved brightness distribution plot\n",
      "2025-06-01 18:55:36,670 - INFO - Saved RGB channel distribution plot\n",
      "2025-06-01 18:55:37,443 - INFO - Saved sample visualization for Normal_Sperm\n",
      "2025-06-01 18:55:38,096 - INFO - Saved sample visualization for Non-Sperm\n",
      "2025-06-01 18:55:38,842 - INFO - Saved sample visualization for Abnormal_Sperm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "stats_df = analyze_dataset(df, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPrepration and Loadering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 19:23:42,140 - INFO - PyTorch version: 2.6.0+cu126\n",
      "2025-06-01 19:23:42,141 - INFO - CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('data_preparation.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verify PyTorch installation\n",
    "try:\n",
    "    logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "except AttributeError as e:\n",
    "    logger.error(f\"PyTorch installation issue: {e}\")\n",
    "    raise\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpermMorphologyDataset:\n",
    "    def __init__(self, df, transform=None, phase='train', expected_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Initialize the Sperm Morphologyology Dataset.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with image paths and labels\n",
    "            transform (A.Compose, optional): Albumentations transformation pipeline\n",
    "            phase (str): Dataset phase ('train', 'validation', 'test')\n",
    "            expected_size (tuple): Expected image size (height, width)\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        self.expected_size = expected_size\n",
    "        self.class_to_idx = {'Normal_Sperm': 0, 'Non-Sperm': 1, 'Abnormal_Sperm': 2}\n",
    "        valid_indices, invalid_images = self._validate_images()\n",
    "        self.df = self.df.iloc[valid_indices].reset_index(drop=True)\n",
    "        self.invalid_images = invalid_images  # Store invalid_images as instance variable\n",
    "        if self.invalid_images:\n",
    "            logger.warning(f\"Found {len(self.invalid_images)} invalid images in {self.phase} set\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label_str = self.df.iloc[idx]['class_label']\n",
    "        try:\n",
    "            label = self.class_to_idx[label_str]\n",
    "        except KeyError:\n",
    "            logger.error(f\"Unknown class label '{label_str}' at index {idx}\")\n",
    "            raise ValueError(f\"Class label '{label_str}' not found in class_to_idx\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def _validate_images(self):\n",
    "        valid_indices = []\n",
    "        invalid_images = []\n",
    "        validate_transform = A.Compose([\n",
    "            A.Resize(height=self.expected_size[0], width=self.expected_size[1]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        for idx in range(len(self.df)):\n",
    "            img_path = self.df.iloc[idx]['image_path']\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    raise ValueError(\"Failed to load image\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                transformed = validate_transform(image=img)\n",
    "                img_transformed = transformed['image']\n",
    "                if img_transformed.shape[1:] != self.expected_size:\n",
    "                    raise ValueError(f\"Transformed image size {img_transformed.shape[1:]} != {self.expected_size}\")\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Invalid image at index {idx}: {img_path}, error: {e}\")\n",
    "                invalid_images.append({'index': idx, 'path': img_path, 'error': str(e)})\n",
    "        logger.info(f\"Validated {len(valid_indices)}/{len(self.df)} images in {self.phase} set\")\n",
    "        return valid_indices, invalid_images\n",
    "\n",
    "        \n",
    "def get_transforms(phase='train', image_size=(224, 224)):\n",
    "    if phase == 'train':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=image_size[0], width=image_size[1]),  # Ensure all images are 224x224\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=30, p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:  # validation or test\n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=image_size[0], width=image_size[1]),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    return transform\n",
    "\n",
    "def create_data_loaders(df, batch_size=32, image_size=(224, 224), random_seed=42, num_workers=0):\n",
    "    \"\"\"\n",
    "    Create PyTorch DataLoaders for training, validation, and testing.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with image paths, class labels, and splits.\n",
    "        batch_size (int): Batch size for data loaders.\n",
    "        image_size (tuple): Target image size (height, width).\n",
    "        random_seed (int): Seed for reproducibility.\n",
    "        num_workers (int): Number of subprocesses for data loading.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of DataLoader objects for 'train', 'val', and 'test'.\n",
    "    \"\"\"\n",
    "    # Set random seeds\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    # Split DataFrame by pre-defined splits\n",
    "    splits = ['train', 'validation', 'test']\n",
    "    datasets = {}\n",
    "    invalid_images_all = []\n",
    "    for split in splits:\n",
    "        split_df = df[df['split'] == split].reset_index(drop=True)\n",
    "        if split_df.empty:\n",
    "            logger.error(f\"No data found for {split} split\")\n",
    "            raise ValueError(f\"Empty {split} split\")\n",
    "        datasets[split] = SpermMorphologyDataset(\n",
    "            split_df,\n",
    "            transform=get_transforms(phase='train' if split == 'train' else 'val', image_size=image_size),\n",
    "            phase=split,\n",
    "            expected_size=image_size\n",
    "        )\n",
    "        invalid_images_all.extend(datasets[split].invalid_images)\n",
    "        logger.info(f\"{split.capitalize()} set: {len(datasets[split])} images\")\n",
    "\n",
    "    # Save invalid images report\n",
    "    if invalid_images_all:\n",
    "        invalid_df = pd.DataFrame(invalid_images_all)\n",
    "        invalid_df.to_csv(os.path.join(save_dir, 'invalid_images.csv'), index=False)\n",
    "        logger.info(f\"Saved invalid images report to {os.path.join(save_dir, 'invalid_images.csv')}\")\n",
    "\n",
    "    # Create data loaders\n",
    "    data_loaders = {}\n",
    "    for split in splits:\n",
    "        data_loaders[split] = DataLoader(\n",
    "            datasets[split],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(split == 'train'),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=(split == 'train')  # Drop last incomplete batch for training\n",
    "        )\n",
    "\n",
    "    return data_loaders\n",
    "\n",
    "def visualize_samples(data_loaders, save_dir, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each DataLoader.\n",
    "\n",
    "    Args:\n",
    "        data_loaders (dict): Dictionary of DataLoaders.\n",
    "        save_dir (str): Directory to save visualizations.\n",
    "        num_samples (int): Number of samples per class to visualize.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    class_names = ['Normal_Sperm', 'Non_Sperm', 'Abnormal_Sperm']\n",
    "    \n",
    "    for phase in data_loaders:\n",
    "        plt.figure(figsize=(15, 5*num_samples))\n",
    "        samples_per_class = {0: 0, 1: 0, 2: 0}\n",
    "        plot_idx = 1\n",
    "        \n",
    "        for images, labels in data_loaders[phase]:\n",
    "            for img, lbl in zip(images, labels):\n",
    "                if samples_per_class[lbl.item()] < num_samples:\n",
    "                    # Denormalize for visualization\n",
    "                    img_np = img.permute(1, 2, 0).numpy()\n",
    "                    mean = np.array([0.485, 0.456, 0.406])\n",
    "                    std = np.array([0.229, 0.224, 0.225])\n",
    "                    img_np = std * img_np + mean\n",
    "                    img_np = np.clip(img_np, 0, 1)\n",
    "                    \n",
    "                    plt.subplot(num_samples, 3, plot_idx)\n",
    "                    plt.imshow(img_np)\n",
    "                    plt.title(f\"{phase.capitalize()}: {class_names[lbl.item()]}\")\n",
    "                    plt.axis('off')\n",
    "                    samples_per_class[lbl.item()] += 1\n",
    "                    plot_idx += 1\n",
    "                \n",
    "                if all(count >= num_samples for count in samples_per_class.values()):\n",
    "                    break\n",
    "            if all(count >= num_samples for count in samples_per_class.values()):\n",
    "                break\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{phase}_samples.png\"))\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved {phase} sample visualization\")\n",
    "\n",
    "def validate_data_loaders(data_loaders):\n",
    "    \"\"\"\n",
    "    Validate DataLoader outputs and log batch statistics.\n",
    "\n",
    "    Args:\n",
    "        data_loaders (dict): Dictionary of DataLoaders.\n",
    "    \"\"\"\n",
    "    for phase, loader in data_loaders.items():\n",
    "        try:\n",
    "            batch_count = 0\n",
    "            class_counts = {0: 0, 1: 0, 2: 0}\n",
    "            for images, labels in loader:\n",
    "                batch_count += 1\n",
    "                logger.info(f\"{phase.capitalize()} batch {batch_count} - Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "                for lbl in labels:\n",
    "                    class_counts[lbl.item()] += 1\n",
    "                if batch_count == 1:  # Log first batch only for brevity\n",
    "                    break\n",
    "            logger.info(f\"{phase.capitalize()} class distribution in first batch: {class_counts}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error validating {phase} DataLoader: {e}\")\n",
    "            raise\n",
    "\n",
    "def save_preparation_report(df, data_loaders, save_dir):\n",
    "    \"\"\"\n",
    "    Save a report summarizing data preparation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        data_loaders (dict): Dictionary of DataLoaders.\n",
    "        save_dir (str): Directory to save report.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    report_path = os.path.join(save_dir, \"data_preparation_report.txt\")\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"Sperm Morphology Dataset Preparation Report\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Total images: {len(df)}\\n\")\n",
    "        for split in ['train', 'validation', 'test']:\n",
    "            split_count = len(df[df['split'] == split])\n",
    "            f.write(f\"{split.capitalize()} set: {split_count} images\\n\")\n",
    "            for cls in ['Normal_Sperm', 'Non_Sperm', 'Abnormal_Sperm']:\n",
    "                cls_count = len(df[(df['split'] == split) & (df['class_label'] == cls)])\n",
    "                f.write(f\"  {cls}: {cls_count} images\\n\")\n",
    "        f.write(\"\\nBatch sizes:\\n\")\n",
    "        for phase, loader in data_loaders.items():\n",
    "            f.write(f\"{phase.capitalize()}: {loader.batch_size}\\n\")\n",
    "    \n",
    "    logger.info(f\"Saved preparation report to {report_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 19:23:44,062 - INFO - Validated 3000/3000 images in train set\n",
      "2025-06-01 19:23:44,062 - INFO - Train set: 3000 images\n",
      "2025-06-01 19:23:44,424 - INFO - Validated 600/600 images in validation set\n",
      "2025-06-01 19:23:44,430 - INFO - Validation set: 600 images\n",
      "2025-06-01 19:23:44,779 - INFO - Validated 600/600 images in test set\n",
      "2025-06-01 19:23:44,783 - INFO - Test set: 600 images\n",
      "2025-06-01 19:23:46,036 - INFO - Train batch 1 - Images shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32])\n",
      "2025-06-01 19:23:46,074 - INFO - Train class distribution in first batch: {0: 10, 1: 14, 2: 8}\n",
      "2025-06-01 19:23:46,144 - INFO - Validation batch 1 - Images shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32])\n",
      "2025-06-01 19:23:46,144 - INFO - Validation class distribution in first batch: {0: 32, 1: 0, 2: 0}\n",
      "2025-06-01 19:23:46,206 - INFO - Test batch 1 - Images shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32])\n",
      "2025-06-01 19:23:46,206 - INFO - Test class distribution in first batch: {0: 32, 1: 0, 2: 0}\n",
      "2025-06-01 19:23:49,162 - INFO - Saved train sample visualization\n",
      "2025-06-01 19:23:51,918 - INFO - Saved validation sample visualization\n",
      "2025-06-01 19:23:54,682 - INFO - Saved test sample visualization\n",
      "2025-06-01 19:23:54,697 - INFO - Saved preparation report to O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\\data_preparation_report.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_path = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\\dataset.csv\"\n",
    "# save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\"\n",
    "\n",
    "# try:\n",
    "#     df = pd.read_csv(df_path)\n",
    "# except FileNotFoundError:\n",
    "#     logger.error(f\"Dataset CSV not found at {df_path}\")\n",
    "#     raise\n",
    "\n",
    "# Create DataLoaders\n",
    "data_loaders = create_data_loaders(\n",
    "    df,\n",
    "    batch_size=32,  # Reverted to 32 for stability\n",
    "    image_size=(224, 224),\n",
    "    random_seed=42,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Validate DataLoaders\n",
    "validate_data_loaders(data_loaders)\n",
    "\n",
    "# Visualize samples\n",
    "visualize_samples(data_loaders, save_dir, num_samples=3)\n",
    "\n",
    "# Save preparation report\n",
    "save_preparation_report(df, data_loaders, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 19:24:57,261 - INFO - Using device: cuda\n",
      "2025-06-01 19:24:57,261 - INFO - PyTorch version: 2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import torchvision.models as models\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Model Definitions\n",
    "def get_efficientnet_b0(num_classes=3):\n",
    "    \"\"\"Initialize EfficientNet-B0 with pre-trained weights.\"\"\"\n",
    "    model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "    # Modify classifier for 3 classes\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_mobilenet_v3_small(num_classes=3):\n",
    "    \"\"\"Initialize MobileNetV3-Small with pre-trained weights.\"\"\"\n",
    "    model = models.mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
    "    # Modify classifier for 3 classes\n",
    "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Evaluation Metrics\n",
    "def compute_metrics(outputs, labels):\n",
    "    \"\"\"Compute accuracy and F1-score.\"\"\"\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return accuracy, f1, preds, labels\n",
    "\n",
    "# Visualization Helper Functions\n",
    "def plot_metrics(history, save_dir, model_name):\n",
    "    \"\"\"Plot training and validation metrics.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{model_name} Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, history['val_f1'], label='Val F1')\n",
    "    plt.title(f'{model_name} F1 Score per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_training_metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(all_preds, all_labels, class_names, save_dir, model_name):\n",
    "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(save_dir, f'{model_name}_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, model_name, train_loader, val_loader, test_loader, num_epochs=50, lr=1e-3, patience=10, save_dir=\"models\"):\n",
    "    \"\"\"Train the model with early stopping, scheduler, and evaluation.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    try:\n",
    "        model = model.to(device)\n",
    "        logger.info(f\"{model_name} moved to {device}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to move {model_name} to {device}: {e}\")\n",
    "        raise\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': [], 'val_f1': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        val_f1 = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        val_bar = tqdm(val_loader, desc=f\"{model_name} Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                accuracy, f1, preds, lbls = compute_metrics(outputs, labels)\n",
    "                val_accuracy += accuracy * images.size(0)\n",
    "                val_f1 += f1 * images.size(0)\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(lbls)\n",
    "                val_bar.set_postfix(loss=loss.item(), accuracy=accuracy)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy /= len(val_loader.dataset)\n",
    "        val_f1 /= len(val_loader.dataset)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        logger.info(f\"{model_name} Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}\")\n",
    "        logger.info(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save metrics to CSV\n",
    "        metrics_df = pd.DataFrame(history)\n",
    "        metrics_df.to_csv(os.path.join(save_dir, f'{model_name}_training_metrics.csv'), index=False)\n",
    "\n",
    "        # Plot metrics\n",
    "        plot_metrics(history, save_dir, model_name)\n",
    "\n",
    "        # Plot confusion matrix for validation set in final epoch\n",
    "        if epoch == num_epochs - 1:\n",
    "            plot_confusion_matrix(all_preds, all_labels, ['Normal_Sperm', 'Non_Sperm', 'Abnormal_Sperm'], save_dir, model_name)\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping and checkpointing\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"{model_name}_best_model.pth\"))\n",
    "            logger.info(f\"Saved best {model_name} model\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                logger.info(f\"Early stopping triggered for {model_name}\")\n",
    "                break\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    test_f1 = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_bar = tqdm(test_loader, desc=f\"{model_name} [Test]\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            accuracy, f1, preds, lbls = compute_metrics(outputs, labels)\n",
    "            test_accuracy += accuracy * images.size(0)\n",
    "            test_f1 += f1 * images.size(0)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(lbls)\n",
    "            test_bar.set_postfix(loss=loss.item(), accuracy=accuracy)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    test_f1 /= len(test_loader.dataset)\n",
    "    logger.info(f\"{model_name} Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "    # Save test confusion matrix\n",
    "    plot_confusion_matrix(all_preds, all_labels, ['Normal_Sperm', 'Non_Sperm', 'Abnormal_Sperm'], save_dir, f\"{model_name}_test\")\n",
    "\n",
    "    # Save test metrics\n",
    "    test_metrics = {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "    pd.DataFrame([test_metrics]).to_csv(os.path.join(save_dir, f'{model_name}_test_metrics.csv'), index=False)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficientnet_b0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 19:25:15,258 - INFO - EfficientNetB0 moved to cuda\n",
      "C:\\Users\\alira\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "EfficientNetB0 Epoch 1/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.25it/s, loss=0.363]\n",
      "EfficientNetB0 Epoch 1/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.37it/s, accuracy=0.917, loss=0.101]\n",
      "2025-06-01 19:25:45,588 - INFO - EfficientNetB0 Epoch 1/50 - Train Loss: 0.5678\n",
      "2025-06-01 19:25:45,588 - INFO - Validation Loss: 0.5976, Accuracy: 0.7917, F1: 0.8694\n",
      "2025-06-01 19:25:46,144 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 2/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.39it/s, loss=0.376]\n",
      "EfficientNetB0 Epoch 2/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.06it/s, accuracy=0.875, loss=0.38]  \n",
      "2025-06-01 19:26:15,126 - INFO - EfficientNetB0 Epoch 2/50 - Train Loss: 0.4279\n",
      "2025-06-01 19:26:15,126 - INFO - Validation Loss: 0.3196, Accuracy: 0.8917, F1: 0.9386\n",
      "2025-06-01 19:26:15,683 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 3/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.40it/s, loss=0.295]\n",
      "EfficientNetB0 Epoch 3/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.72it/s, accuracy=0.75, loss=0.655]  \n",
      "2025-06-01 19:26:44,695 - INFO - EfficientNetB0 Epoch 3/50 - Train Loss: 0.3677\n",
      "2025-06-01 19:26:44,695 - INFO - Validation Loss: 0.3720, Accuracy: 0.8650, F1: 0.9167\n",
      "EfficientNetB0 Epoch 4/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.38it/s, loss=0.7]  \n",
      "EfficientNetB0 Epoch 4/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.09it/s, accuracy=0.917, loss=0.343] \n",
      "2025-06-01 19:27:14,296 - INFO - EfficientNetB0 Epoch 4/50 - Train Loss: 0.3440\n",
      "2025-06-01 19:27:14,301 - INFO - Validation Loss: 0.3192, Accuracy: 0.8900, F1: 0.9349\n",
      "2025-06-01 19:27:15,062 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 5/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.36it/s, loss=0.423] \n",
      "EfficientNetB0 Epoch 5/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.82it/s, accuracy=0.917, loss=0.228] \n",
      "2025-06-01 19:27:44,393 - INFO - EfficientNetB0 Epoch 5/50 - Train Loss: 0.2926\n",
      "2025-06-01 19:27:44,393 - INFO - Validation Loss: 0.2747, Accuracy: 0.8950, F1: 0.9381\n",
      "2025-06-01 19:27:45,006 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 6/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.42it/s, loss=0.155] \n",
      "EfficientNetB0 Epoch 6/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.21it/s, accuracy=0.833, loss=0.442] \n",
      "2025-06-01 19:28:13,773 - INFO - EfficientNetB0 Epoch 6/50 - Train Loss: 0.2821\n",
      "2025-06-01 19:28:13,780 - INFO - Validation Loss: 0.2840, Accuracy: 0.9067, F1: 0.9464\n",
      "EfficientNetB0 Epoch 7/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.29it/s, loss=0.06] \n",
      "EfficientNetB0 Epoch 7/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.65it/s, accuracy=0.917, loss=0.273] \n",
      "2025-06-01 19:28:44,028 - INFO - EfficientNetB0 Epoch 7/50 - Train Loss: 0.2697\n",
      "2025-06-01 19:28:44,028 - INFO - Validation Loss: 0.2973, Accuracy: 0.9050, F1: 0.9466\n",
      "EfficientNetB0 Epoch 8/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.37it/s, loss=0.37]  \n",
      "EfficientNetB0 Epoch 8/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.52it/s, accuracy=0.792, loss=0.557]\n",
      "2025-06-01 19:29:13,740 - INFO - EfficientNetB0 Epoch 8/50 - Train Loss: 0.2711\n",
      "2025-06-01 19:29:13,740 - INFO - Validation Loss: 0.2873, Accuracy: 0.9017, F1: 0.9444\n",
      "EfficientNetB0 Epoch 9/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.24it/s, loss=0.173] \n",
      "EfficientNetB0 Epoch 9/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.21it/s, accuracy=0.875, loss=0.428]\n",
      "2025-06-01 19:29:44,553 - INFO - EfficientNetB0 Epoch 9/50 - Train Loss: 0.2662\n",
      "2025-06-01 19:29:44,553 - INFO - Validation Loss: 0.2884, Accuracy: 0.9067, F1: 0.9449\n",
      "EfficientNetB0 Epoch 10/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.30it/s, loss=0.138] \n",
      "EfficientNetB0 Epoch 10/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.95it/s, accuracy=0.917, loss=0.169] \n",
      "2025-06-01 19:30:14,907 - INFO - EfficientNetB0 Epoch 10/50 - Train Loss: 0.2140\n",
      "2025-06-01 19:30:14,907 - INFO - Validation Loss: 0.2422, Accuracy: 0.9183, F1: 0.9539\n",
      "2025-06-01 19:30:15,474 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 11/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.32it/s, loss=0.176] \n",
      "EfficientNetB0 Epoch 11/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.06it/s, accuracy=0.833, loss=0.417]\n",
      "2025-06-01 19:30:45,059 - INFO - EfficientNetB0 Epoch 11/50 - Train Loss: 0.1750\n",
      "2025-06-01 19:30:45,059 - INFO - Validation Loss: 0.2549, Accuracy: 0.9233, F1: 0.9563\n",
      "EfficientNetB0 Epoch 12/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.36it/s, loss=0.0541]\n",
      "EfficientNetB0 Epoch 12/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.40it/s, accuracy=0.875, loss=0.315] \n",
      "2025-06-01 19:31:14,780 - INFO - EfficientNetB0 Epoch 12/50 - Train Loss: 0.1509\n",
      "2025-06-01 19:31:14,780 - INFO - Validation Loss: 0.2951, Accuracy: 0.8983, F1: 0.9401\n",
      "EfficientNetB0 Epoch 13/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.38it/s, loss=0.0575]\n",
      "EfficientNetB0 Epoch 13/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.21it/s, accuracy=0.917, loss=0.206]\n",
      "2025-06-01 19:31:44,304 - INFO - EfficientNetB0 Epoch 13/50 - Train Loss: 0.1504\n",
      "2025-06-01 19:31:44,304 - INFO - Validation Loss: 0.2495, Accuracy: 0.9233, F1: 0.9547\n",
      "EfficientNetB0 Epoch 14/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.36it/s, loss=0.163] \n",
      "EfficientNetB0 Epoch 14/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.98it/s, accuracy=0.875, loss=0.346] \n",
      "2025-06-01 19:32:14,061 - INFO - EfficientNetB0 Epoch 14/50 - Train Loss: 0.1399\n",
      "2025-06-01 19:32:14,062 - INFO - Validation Loss: 0.2252, Accuracy: 0.9400, F1: 0.9669\n",
      "2025-06-01 19:32:14,609 - INFO - Saved best EfficientNetB0 model\n",
      "EfficientNetB0 Epoch 15/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.34it/s, loss=0.124] \n",
      "EfficientNetB0 Epoch 15/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.88it/s, accuracy=0.875, loss=0.25]  \n",
      "2025-06-01 19:32:44,063 - INFO - EfficientNetB0 Epoch 15/50 - Train Loss: 0.1280\n",
      "2025-06-01 19:32:44,063 - INFO - Validation Loss: 0.2533, Accuracy: 0.9450, F1: 0.9695\n",
      "EfficientNetB0 Epoch 16/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.39it/s, loss=0.28]   \n",
      "EfficientNetB0 Epoch 16/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.10it/s, accuracy=0.875, loss=0.347]\n",
      "2025-06-01 19:33:13,522 - INFO - EfficientNetB0 Epoch 16/50 - Train Loss: 0.1162\n",
      "2025-06-01 19:33:13,522 - INFO - Validation Loss: 0.3096, Accuracy: 0.9150, F1: 0.9506\n",
      "EfficientNetB0 Epoch 17/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.39it/s, loss=0.0954] \n",
      "EfficientNetB0 Epoch 17/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.56it/s, accuracy=0.833, loss=0.491]\n",
      "2025-06-01 19:33:43,136 - INFO - EfficientNetB0 Epoch 17/50 - Train Loss: 0.1145\n",
      "2025-06-01 19:33:43,136 - INFO - Validation Loss: 0.2806, Accuracy: 0.9383, F1: 0.9651\n",
      "EfficientNetB0 Epoch 18/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.40it/s, loss=0.154] \n",
      "EfficientNetB0 Epoch 18/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.85it/s, accuracy=0.917, loss=0.239] \n",
      "2025-06-01 19:34:12,646 - INFO - EfficientNetB0 Epoch 18/50 - Train Loss: 0.1299\n",
      "2025-06-01 19:34:12,646 - INFO - Validation Loss: 0.2620, Accuracy: 0.9383, F1: 0.9637\n",
      "EfficientNetB0 Epoch 19/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.33it/s, loss=0.0903] \n",
      "EfficientNetB0 Epoch 19/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.88it/s, accuracy=0.833, loss=0.425] \n",
      "2025-06-01 19:34:42,684 - INFO - EfficientNetB0 Epoch 19/50 - Train Loss: 0.0958\n",
      "2025-06-01 19:34:42,684 - INFO - Validation Loss: 0.2692, Accuracy: 0.9400, F1: 0.9654\n",
      "EfficientNetB0 Epoch 20/50 [Train]: 100%|██████████| 93/93 [00:28<00:00,  3.31it/s, loss=0.0336] \n",
      "EfficientNetB0 Epoch 20/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.11it/s, accuracy=0.833, loss=0.287] \n",
      "2025-06-01 19:35:12,888 - INFO - EfficientNetB0 Epoch 20/50 - Train Loss: 0.0807\n",
      "2025-06-01 19:35:12,893 - INFO - Validation Loss: 0.2812, Accuracy: 0.9367, F1: 0.9634\n",
      "EfficientNetB0 Epoch 21/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.33it/s, loss=0.0473] \n",
      "EfficientNetB0 Epoch 21/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 12.38it/s, accuracy=0.875, loss=0.3]   \n",
      "2025-06-01 19:35:42,920 - INFO - EfficientNetB0 Epoch 21/50 - Train Loss: 0.0826\n",
      "2025-06-01 19:35:42,922 - INFO - Validation Loss: 0.2654, Accuracy: 0.9433, F1: 0.9672\n",
      "EfficientNetB0 Epoch 22/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.37it/s, loss=0.0316] \n",
      "EfficientNetB0 Epoch 22/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.77it/s, accuracy=0.833, loss=0.481]\n",
      "2025-06-01 19:36:12,637 - INFO - EfficientNetB0 Epoch 22/50 - Train Loss: 0.0837\n",
      "2025-06-01 19:36:12,643 - INFO - Validation Loss: 0.2566, Accuracy: 0.9367, F1: 0.9642\n",
      "EfficientNetB0 Epoch 23/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.41it/s, loss=0.125]  \n",
      "EfficientNetB0 Epoch 23/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.95it/s, accuracy=0.875, loss=0.381]\n",
      "2025-06-01 19:36:42,015 - INFO - EfficientNetB0 Epoch 23/50 - Train Loss: 0.0635\n",
      "2025-06-01 19:36:42,015 - INFO - Validation Loss: 0.2522, Accuracy: 0.9500, F1: 0.9721\n",
      "EfficientNetB0 Epoch 24/50 [Train]: 100%|██████████| 93/93 [00:27<00:00,  3.40it/s, loss=0.0355] \n",
      "EfficientNetB0 Epoch 24/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 11.80it/s, accuracy=0.917, loss=0.36] \n",
      "2025-06-01 19:37:11,437 - INFO - EfficientNetB0 Epoch 24/50 - Train Loss: 0.0666\n",
      "2025-06-01 19:37:11,437 - INFO - Validation Loss: 0.2630, Accuracy: 0.9483, F1: 0.9704\n",
      "2025-06-01 19:37:11,900 - INFO - Early stopping triggered for EfficientNetB0\n",
      "EfficientNetB0 [Test]: 100%|██████████| 19/19 [00:01<00:00, 12.14it/s, accuracy=0.833, loss=0.819] \n",
      "2025-06-01 19:37:13,472 - INFO - EfficientNetB0 Test Loss: 0.1688, Accuracy: 0.9567, F1: 0.9764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Paths\n",
    "# df_path = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\plots\\dataset.csv\"\n",
    "# save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\Sperm Morphology Colorized\\models\"\n",
    "\n",
    "# # Load DataFrame\n",
    "# try:\n",
    "#     df = pd.read_csv(df_path)\n",
    "# except FileNotFoundError:\n",
    "#     logger.error(f\"Dataset CSV not found at {df_path}\")\n",
    "#     raise\n",
    "\n",
    "# # Create DataLoaders\n",
    "# data_loaders = create_data_loaders(df, batch_size=32, image_size=(224, 224), random_seed=42, num_workers=0)\n",
    "\n",
    "# Train EfficientNet-B0\n",
    "efficientnet = get_efficientnet_b0(num_classes=3)\n",
    "efficientnet, eff_history = train_model(\n",
    "    efficientnet,\n",
    "    model_name=\"EfficientNetB0\",\n",
    "    train_loader=data_loaders['train'],\n",
    "    val_loader=data_loaders['validation'],\n",
    "    test_loader=data_loaders['test'],\n",
    "    num_epochs=50,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenet_v3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to C:\\Users\\alira/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:04<00:00, 2.37MB/s]\n",
      "2025-06-01 19:38:20,619 - INFO - MobileNetV3Small moved to cuda\n",
      "C:\\Users\\alira\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "MobileNetV3Small Epoch 1/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.35it/s, loss=0.726]\n",
      "MobileNetV3Small Epoch 1/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.39it/s, accuracy=0.667, loss=1.21] \n",
      "2025-06-01 19:38:43,324 - INFO - MobileNetV3Small Epoch 1/50 - Train Loss: 0.5407\n",
      "2025-06-01 19:38:43,324 - INFO - Validation Loss: 0.6395, Accuracy: 0.8133, F1: 0.8781\n",
      "2025-06-01 19:38:44,420 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 2/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.29it/s, loss=0.322]\n",
      "MobileNetV3Small Epoch 2/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.24it/s, accuracy=0.917, loss=0.192]\n",
      "2025-06-01 19:39:07,437 - INFO - MobileNetV3Small Epoch 2/50 - Train Loss: 0.3811\n",
      "2025-06-01 19:39:07,437 - INFO - Validation Loss: 0.7762, Accuracy: 0.7917, F1: 0.8717\n",
      "MobileNetV3Small Epoch 3/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.33it/s, loss=0.214] \n",
      "MobileNetV3Small Epoch 3/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.63it/s, accuracy=0.583, loss=1.24] \n",
      "2025-06-01 19:39:30,820 - INFO - MobileNetV3Small Epoch 3/50 - Train Loss: 0.3462\n",
      "2025-06-01 19:39:30,825 - INFO - Validation Loss: 0.5873, Accuracy: 0.8367, F1: 0.9010\n",
      "2025-06-01 19:39:31,382 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 4/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.30it/s, loss=0.634] \n",
      "MobileNetV3Small Epoch 4/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.88it/s, accuracy=0.958, loss=0.0809]\n",
      "2025-06-01 19:39:54,381 - INFO - MobileNetV3Small Epoch 4/50 - Train Loss: 0.3243\n",
      "2025-06-01 19:39:54,381 - INFO - Validation Loss: 0.6655, Accuracy: 0.8250, F1: 0.8900\n",
      "MobileNetV3Small Epoch 5/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.40it/s, loss=0.165] \n",
      "MobileNetV3Small Epoch 5/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.54it/s, accuracy=0.792, loss=0.652]\n",
      "2025-06-01 19:40:17,267 - INFO - MobileNetV3Small Epoch 5/50 - Train Loss: 0.2892\n",
      "2025-06-01 19:40:17,267 - INFO - Validation Loss: 0.3475, Accuracy: 0.8833, F1: 0.9319\n",
      "2025-06-01 19:40:17,802 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 6/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.40it/s, loss=0.191] \n",
      "MobileNetV3Small Epoch 6/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.39it/s, accuracy=0.792, loss=0.542] \n",
      "2025-06-01 19:40:40,258 - INFO - MobileNetV3Small Epoch 6/50 - Train Loss: 0.2601\n",
      "2025-06-01 19:40:40,258 - INFO - Validation Loss: 0.2871, Accuracy: 0.9033, F1: 0.9437\n",
      "2025-06-01 19:40:40,812 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 7/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.24it/s, loss=0.308] \n",
      "MobileNetV3Small Epoch 7/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 15.15it/s, accuracy=0.75, loss=0.708]  \n",
      "2025-06-01 19:41:04,029 - INFO - MobileNetV3Small Epoch 7/50 - Train Loss: 0.2529\n",
      "2025-06-01 19:41:04,029 - INFO - Validation Loss: 0.3383, Accuracy: 0.8917, F1: 0.9338\n",
      "MobileNetV3Small Epoch 8/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.38it/s, loss=0.302] \n",
      "MobileNetV3Small Epoch 8/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.48it/s, accuracy=0.875, loss=0.251]\n",
      "2025-06-01 19:41:27,037 - INFO - MobileNetV3Small Epoch 8/50 - Train Loss: 0.2331\n",
      "2025-06-01 19:41:27,045 - INFO - Validation Loss: 0.3980, Accuracy: 0.8867, F1: 0.9336\n",
      "MobileNetV3Small Epoch 9/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.38it/s, loss=0.336] \n",
      "MobileNetV3Small Epoch 9/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 15.43it/s, accuracy=0.792, loss=0.435] \n",
      "2025-06-01 19:41:49,965 - INFO - MobileNetV3Small Epoch 9/50 - Train Loss: 0.2466\n",
      "2025-06-01 19:41:49,965 - INFO - Validation Loss: 0.3370, Accuracy: 0.8850, F1: 0.9342\n",
      "MobileNetV3Small Epoch 10/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.37it/s, loss=0.324] \n",
      "MobileNetV3Small Epoch 10/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.31it/s, accuracy=0.958, loss=0.0934]\n",
      "2025-06-01 19:42:13,125 - INFO - MobileNetV3Small Epoch 10/50 - Train Loss: 0.2077\n",
      "2025-06-01 19:42:13,125 - INFO - Validation Loss: 0.5717, Accuracy: 0.8183, F1: 0.8803\n",
      "MobileNetV3Small Epoch 11/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.37it/s, loss=0.531] \n",
      "MobileNetV3Small Epoch 11/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.83it/s, accuracy=0.75, loss=0.489] \n",
      "2025-06-01 19:42:36,158 - INFO - MobileNetV3Small Epoch 11/50 - Train Loss: 0.1761\n",
      "2025-06-01 19:42:36,158 - INFO - Validation Loss: 0.2535, Accuracy: 0.9217, F1: 0.9550\n",
      "2025-06-01 19:42:37,047 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 12/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.38it/s, loss=0.21]  \n",
      "MobileNetV3Small Epoch 12/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.62it/s, accuracy=0.833, loss=0.329]\n",
      "2025-06-01 19:42:59,573 - INFO - MobileNetV3Small Epoch 12/50 - Train Loss: 0.1540\n",
      "2025-06-01 19:42:59,573 - INFO - Validation Loss: 0.2633, Accuracy: 0.9183, F1: 0.9536\n",
      "MobileNetV3Small Epoch 13/50 [Train]: 100%|██████████| 93/93 [00:20<00:00,  4.46it/s, loss=0.243] \n",
      "MobileNetV3Small Epoch 13/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.76it/s, accuracy=0.833, loss=0.359] \n",
      "2025-06-01 19:43:22,200 - INFO - MobileNetV3Small Epoch 13/50 - Train Loss: 0.1490\n",
      "2025-06-01 19:43:22,200 - INFO - Validation Loss: 0.2273, Accuracy: 0.9250, F1: 0.9561\n",
      "2025-06-01 19:43:22,694 - INFO - Saved best MobileNetV3Small model\n",
      "MobileNetV3Small Epoch 14/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.37it/s, loss=0.127] \n",
      "MobileNetV3Small Epoch 14/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.66it/s, accuracy=0.833, loss=0.605]\n",
      "2025-06-01 19:43:45,270 - INFO - MobileNetV3Small Epoch 14/50 - Train Loss: 0.1241\n",
      "2025-06-01 19:43:45,270 - INFO - Validation Loss: 0.2667, Accuracy: 0.9283, F1: 0.9586\n",
      "MobileNetV3Small Epoch 15/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.41it/s, loss=0.035] \n",
      "MobileNetV3Small Epoch 15/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.37it/s, accuracy=0.875, loss=0.501] \n",
      "2025-06-01 19:44:08,271 - INFO - MobileNetV3Small Epoch 15/50 - Train Loss: 0.1246\n",
      "2025-06-01 19:44:08,272 - INFO - Validation Loss: 0.2666, Accuracy: 0.9183, F1: 0.9538\n",
      "MobileNetV3Small Epoch 16/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.28it/s, loss=0.134] \n",
      "MobileNetV3Small Epoch 16/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.14it/s, accuracy=0.875, loss=0.38] \n",
      "2025-06-01 19:44:31,895 - INFO - MobileNetV3Small Epoch 16/50 - Train Loss: 0.1204\n",
      "2025-06-01 19:44:31,896 - INFO - Validation Loss: 0.3370, Accuracy: 0.9167, F1: 0.9518\n",
      "MobileNetV3Small Epoch 17/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.28it/s, loss=0.347]  \n",
      "MobileNetV3Small Epoch 17/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.30it/s, accuracy=0.875, loss=0.463]\n",
      "2025-06-01 19:44:55,467 - INFO - MobileNetV3Small Epoch 17/50 - Train Loss: 0.1291\n",
      "2025-06-01 19:44:55,467 - INFO - Validation Loss: 0.2798, Accuracy: 0.9350, F1: 0.9623\n",
      "MobileNetV3Small Epoch 18/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.33it/s, loss=0.00792]\n",
      "MobileNetV3Small Epoch 18/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.18it/s, accuracy=0.875, loss=0.397]\n",
      "2025-06-01 19:45:18,964 - INFO - MobileNetV3Small Epoch 18/50 - Train Loss: 0.0845\n",
      "2025-06-01 19:45:18,965 - INFO - Validation Loss: 0.2495, Accuracy: 0.9317, F1: 0.9605\n",
      "MobileNetV3Small Epoch 19/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.38it/s, loss=0.0505] \n",
      "MobileNetV3Small Epoch 19/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.07it/s, accuracy=0.833, loss=0.308] \n",
      "2025-06-01 19:45:42,127 - INFO - MobileNetV3Small Epoch 19/50 - Train Loss: 0.0827\n",
      "2025-06-01 19:45:42,127 - INFO - Validation Loss: 0.2576, Accuracy: 0.9250, F1: 0.9554\n",
      "MobileNetV3Small Epoch 20/50 [Train]: 100%|██████████| 93/93 [00:22<00:00,  4.14it/s, loss=0.0779] \n",
      "MobileNetV3Small Epoch 20/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.67it/s, accuracy=0.833, loss=0.634]\n",
      "2025-06-01 19:46:06,498 - INFO - MobileNetV3Small Epoch 20/50 - Train Loss: 0.0774\n",
      "2025-06-01 19:46:06,499 - INFO - Validation Loss: 0.2716, Accuracy: 0.9250, F1: 0.9575\n",
      "MobileNetV3Small Epoch 21/50 [Train]: 100%|██████████| 93/93 [00:22<00:00,  4.07it/s, loss=0.0653] \n",
      "MobileNetV3Small Epoch 21/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.61it/s, accuracy=0.833, loss=0.727]\n",
      "2025-06-01 19:46:31,304 - INFO - MobileNetV3Small Epoch 21/50 - Train Loss: 0.0758\n",
      "2025-06-01 19:46:31,304 - INFO - Validation Loss: 0.2697, Accuracy: 0.9383, F1: 0.9646\n",
      "MobileNetV3Small Epoch 22/50 [Train]: 100%|██████████| 93/93 [00:21<00:00,  4.24it/s, loss=0.0156] \n",
      "MobileNetV3Small Epoch 22/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 14.08it/s, accuracy=0.875, loss=0.519]\n",
      "2025-06-01 19:46:55,132 - INFO - MobileNetV3Small Epoch 22/50 - Train Loss: 0.0783\n",
      "2025-06-01 19:46:55,133 - INFO - Validation Loss: 0.2424, Accuracy: 0.9350, F1: 0.9623\n",
      "MobileNetV3Small Epoch 23/50 [Train]: 100%|██████████| 93/93 [00:22<00:00,  4.21it/s, loss=0.103]  \n",
      "MobileNetV3Small Epoch 23/50 [Val]: 100%|██████████| 19/19 [00:01<00:00, 13.78it/s, accuracy=0.875, loss=0.581]\n",
      "2025-06-01 19:47:19,100 - INFO - MobileNetV3Small Epoch 23/50 - Train Loss: 0.0614\n",
      "2025-06-01 19:47:19,100 - INFO - Validation Loss: 0.2511, Accuracy: 0.9367, F1: 0.9625\n",
      "2025-06-01 19:47:19,892 - INFO - Early stopping triggered for MobileNetV3Small\n",
      "MobileNetV3Small [Test]: 100%|██████████| 19/19 [00:01<00:00, 12.49it/s, accuracy=0.792, loss=0.696]\n",
      "2025-06-01 19:47:21,418 - INFO - MobileNetV3Small Test Loss: 0.1920, Accuracy: 0.9450, F1: 0.9703\n"
     ]
    }
   ],
   "source": [
    "# Train MobileNetV3-Small\n",
    "mobilenet = get_mobilenet_v3_small(num_classes=3)\n",
    "mobilenet, mob_history = train_model(\n",
    "    mobilenet,\n",
    "    model_name=\"MobileNetV3Small\",\n",
    "    train_loader=data_loaders['train'],\n",
    "    val_loader=data_loaders['validation'],\n",
    "    test_loader=data_loaders['test'],\n",
    "    num_epochs=50,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
